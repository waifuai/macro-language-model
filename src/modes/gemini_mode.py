from waifu_chatbot import WaifuChatbot
from main_transforms import register_transforms
from main_keywords import register_keywords
from typing import Dict, List, Tuple
import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential
from gemini_utils import is_echoed_response, generate_with_retry
from modes.common import setup_gemini_api

def run_gemini_mode(waifu_name: str, debug: bool, max_turns: int = 10) -> None:
    """Runs the chatbot in Gemini mode with full conversation history."""
    if debug:
        print("Entering run_gemini_mode")

    # Setup Gemini API
    genai_instance = setup_gemini_api()
    if genai_instance is None:
        return

    # Initialize the WaifuChatbot
    waifu = WaifuChatbot(waifu_name, debug=debug)
    register_keywords(waifu)
    register_transforms(waifu)

    # System instruction with clear guidance and examples
    system_instruction = (
        f"You are a human user interacting with a chatbot named {waifu_name}. "
        f"Your task is to respond to {waifu_name}'s messages as a typical human user would. "
        f"Do not imitate {waifu_name}'s style, repeat her message, or echo her words. Instead, "
        f"generate varied, engaging, and contextually appropriate responses that advance the conversation. "
        f"Here are some examples:\n"
        f"1. {waifu_name}: 'Senpai, you're back! How was your day?'\n"
        f"   User: 'Hey, it was pretty hectic, but I'm glad to be here now! How about you?'\n"
        f"2. {waifu_name}: 'D-do you need something?'\n"
        f"   User: 'Just wanted to chat and unwind. Got any fun ideas?'\n"
        f"3. {waifu_name}: 'I wonder what the next big trend will be...'\n"
        f"   User: 'Oh, good question! I think virtual reality is going to explode soon. What do you think?'\n"
        f"Always aim to keep the conversation lively and interesting."
    )

    model = genai.GenerativeModel("gemini-2.0-flash", generation_config={"temperature": 0.9, "top_p": 0.95})
    if debug:
        print(f"Model initialized: {model}")

    # Initial greeting from the chatbot
    greeting = waifu.greetings[0]
    print(f"Waifu: {greeting}")

    # Initialize conversation history
    conversation_history = [f"{waifu_name}: {greeting}"]

    # Initial prompt with full history
    prompt = (
        f"{system_instruction}\n\n"
        f"### Conversation History:\n"
        f"{conversation_history[0]}\n"
        f"### Your Task:\n"
        f"Respond as the user in a way that is engaging and advances the conversation. Do not repeat or echo {waifu_name}'s message.\n"
        f"User: "
    )
    if debug:
        print(f"Initial Prompt: {prompt}")

    # Generate initial response
    try:
        if debug: # Add debug check
            print(f"Calling generate_with_retry with initial prompt")
        response = generate_with_retry(model, prompt, greeting)
        if debug:  # Add debug check
            print(f"Initial response received: {response.text}")
    except Exception as e:
        print(f"Error generating initial response: {e}")
        return
    #response = "Placeholder response" # Placeholder

    # Conversation loop for specified turns
    for turn in range(max_turns):
        try:
            # Print and store the user response generated by Gemini
            user_response = response.text
            print(f"User: {user_response}")
            conversation_history.append(f"User: {user_response}")

            # Get and print the waifu's response
            waifu_response = waifu.respond(user_response)
            print(f"Waifu: {waifu_response}")
            conversation_history.append(f"{waifu_name}: {waifu_response}")

            # Check if the conversation should end
            if waifu_response in waifu.farewells:
                break

            # Update prompt with full conversation history
            history_text = "\n".join(conversation_history)
            prompt = (
                f"{system_instruction}\n\n"
                f"### Conversation History:\n"
                f"{history_text}\n"
                f"### Your Task:\n"
                f"Respond as the user in a way that is engaging and advances the conversation. Do not repeat or echo {waifu_name}'s message.\n"
                f"User: "
            )
            if debug:
                print(f"Prompt for turn {turn + 1}: {prompt}")

            # Generate next response and ensure we wait for it
            if debug:  # Add debug check
                print(f"Calling generate_with_retry for turn {turn + 1}")
            response = generate_with_retry(model, prompt, waifu_response)
            if debug:  # Add debug check
                print(f"Response received for turn {turn + 1}: {response.text}")
                print(f"is_echoed_response: {is_echoed_response(response.text, waifu_response)}")
            #response = "Placeholder response" # Placeholder

        except Exception as e:
            print(f"Error in turn {turn + 1}: {e}")
            break